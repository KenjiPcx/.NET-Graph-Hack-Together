@using Microsoft.CognitiveServices.Speech;
@using Microsoft.CognitiveServices.Speech.Audio;
@using ProductiGraph.Shared.Components
@inject IConfiguration configuration
@inject ProjectService projectService
@page "/"

<div class="flex justify-center mb-5">
    <select class="select select-bordered w-full max-w-xs">
        <option disabled selected>Choose a project</option>
        @foreach (var name in projectNames)
        {
            <option>@name</option>
        }
    </select>
</div>
<div class="outline min-h-[62.5vh]">
    @foreach (var message in messages)
    {
        <div class="rounded-xl bg-blue-700 p-3 m-3">@message</div>
    }
</div>
<div class="flex justify-evenly w-full my-5">
    @if (!speaking)
    {
        <button class="btn btn-success btn-sm" @onclick="StartRecording">Start Recording</button>
    }
    else
    {
        <button class="btn btn-error btn-sm" @onclick="StopRecording">Stop Recording</button>
    }
    <button class="btn btn-warning btn-sm" @onclick="ClearMessages">Clear Recording</button>
</div>
<div class="flex flex-col w-3/4 mx-auto justify-center items-center gap-3">
    <button class="btn btn-primary btn-sm" @onclick="ClearMessages">Extract and Refine Todos</button>
    <button class="btn btn-info btn-sm" @onclick="ClearMessages">Add to Microsoft Todo</button>
</div>

@code {
    private bool speaking;
    private SpeechRecognizer? recognizer;
    private string speechKey = "";
    private string speechRegion = "";
    private List<string> messages = new List<string>();
    private List<string> projectNames = new List<string>();

    protected override async Task OnInitializedAsync()
    {
        speechKey = configuration["SPEECH_KEY"]!;
        speechRegion = configuration["SPEECH_REGION"]!;
        var projects = await projectService.GetProjectsAsync();
        projectNames = projects.Select(p => p.Name).ToList();
        await base.OnInitializedAsync();
    }

    private async Task StartRecording()
    {
        var config = SpeechConfig.FromSubscription(speechKey, speechRegion);
        recognizer = new SpeechRecognizer(config);

        recognizer.Recognized += Recognizer_Recognized;
        speaking = true;
        await recognizer.StartContinuousRecognitionAsync();
    }

    private async void Recognizer_Recognized(object sender, SpeechRecognitionEventArgs e)
    {
        messages.Add(e.Result.Text);
        await InvokeAsync(() =>
        {
            StateHasChanged();
        });
    }

    private async Task StopRecording()
    {
        if (recognizer == null)
        {
            return;
        }
        speaking = false;
        await recognizer.StopContinuousRecognitionAsync();
        recognizer.Recognized -= Recognizer_Recognized;
    }

    private void ClearMessages()
    {
        messages = new List<string>();
    }
}

